{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dn3ndra/DeepLearning/blob/main/03.%20Week%203/Assignment/CIFAR_10_Datasets_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zgA_OvhAAhcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADC"
      ],
      "metadata": {
        "id": "2doZKZsIAiI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library jika diperlukan (khusus Google Colab)\n",
        "!pip install torch torchvision scikit-learn matplotlib\n",
        "\n",
        "# Import library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz4NxjCMAjGk",
        "outputId": "02146616-0679-41e8-ef04-d653a454f42f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Gunakan transformasi ini saat ambil data\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Label nama kelas\n",
        "classes = trainset.classes\n"
      ],
      "metadata": {
        "id": "ek8coafXAq94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4feee102-ccae-4e5a-83f2-084a36293321"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 13.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Model 1: CNN (Convolutional Neural Network)"
      ],
      "metadata": {
        "id": "QcZFF9H1BKl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "RyLuHG3PBNly"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Model 2: MLP (Multilayer Perceptron) Vanilla"
      ],
      "metadata": {
        "id": "GyDATU2pBTk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPVanilla(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPVanilla, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 32 * 3, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "Y1p_o3hBBS7N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚙️ Training & Evaluation Function"
      ],
      "metadata": {
        "id": "1VrYaGYRBaXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, loader, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    y_true, y_pred, y_score = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            y_score.extend(probs.cpu().numpy())\n",
        "\n",
        "    return np.array(y_true), np.array(y_pred), np.array(y_score)\n"
      ],
      "metadata": {
        "id": "6DKse3adBcJQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🚀 Jalankan Training untuk CNN"
      ],
      "metadata": {
        "id": "iCCVUAWrBe-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(10):\n",
        "    loss = train(model, optimizer, criterion, trainloader, device)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sViKw99nBgrw",
        "outputId": "d42decbb-5ce3-4bc9-b582-0575b092488a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.5062\n",
            "Epoch 2, Loss: 1.0414\n",
            "Epoch 3, Loss: 0.8603\n",
            "Epoch 4, Loss: 0.7463\n",
            "Epoch 5, Loss: 0.6692\n",
            "Epoch 6, Loss: 0.6103\n",
            "Epoch 7, Loss: 0.5693\n",
            "Epoch 8, Loss: 0.5281\n",
            "Epoch 9, Loss: 0.4927\n",
            "Epoch 10, Loss: 0.4553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Evaluasi CNN"
      ],
      "metadata": {
        "id": "Y8B5D8FzB6AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred, y_score = evaluate(model, testloader, device)\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred, average='macro')\n",
        "rec = recall_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# ROC AUC Macro (multi-class)\n",
        "try:\n",
        "    auc = roc_auc_score(y_true, y_score, multi_class='ovo', average='macro')\n",
        "except:\n",
        "    auc = 'Error (label mismatch)'\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"AUC Score: {auc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH1vyS3AB8jn",
        "outputId": "b2aa8d18-542b-4dd1-810a-633a70a05c99"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8256\n",
            "Precision: 0.8306\n",
            "Recall: 0.8256\n",
            "F1 Score: 0.8232\n",
            "AUC Score: 0.9833068833333335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ CNN Test Accuracy"
      ],
      "metadata": {
        "id": "xhujXfxZCUeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tambahkan akurasi dalam bentuk persen\n",
        "acc_percent = acc * 100\n",
        "print(f\"CNN Test Accuracy : {acc_percent:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HknbMbBCYcM",
        "outputId": "5970b1aa-bc02-468f-8ec0-fa99ddc65248"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Test Accuracy : 82.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🚀 Training untuk MLP Vanilla"
      ],
      "metadata": {
        "id": "8ALglBLgDg52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp = MLPVanilla().to(device)\n",
        "optimizer_mlp = optim.Adam(model_mlp.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    loss = train(model_mlp, optimizer_mlp, criterion, trainloader, device)\n",
        "    print(f\"MLP Epoch {epoch+1}, Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jevPZIIuDgLV",
        "outputId": "90fb1520-6bb2-4ada-b6c9-662c11e3b931"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Epoch 1, Loss: 1.8238\n",
            "MLP Epoch 2, Loss: 1.6499\n",
            "MLP Epoch 3, Loss: 1.5708\n",
            "MLP Epoch 4, Loss: 1.5274\n",
            "MLP Epoch 5, Loss: 1.4931\n",
            "MLP Epoch 6, Loss: 1.4638\n",
            "MLP Epoch 7, Loss: 1.4421\n",
            "MLP Epoch 8, Loss: 1.4246\n",
            "MLP Epoch 9, Loss: 1.4096\n",
            "MLP Epoch 10, Loss: 1.3941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Evaluasi MLP"
      ],
      "metadata": {
        "id": "j3ubs9yVDlLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi MLP\n",
        "y_true_mlp, y_pred_mlp, y_score_mlp = evaluate(model_mlp, testloader, device)\n",
        "\n",
        "acc_mlp = accuracy_score(y_true_mlp, y_pred_mlp)\n",
        "prec_mlp = precision_score(y_true_mlp, y_pred_mlp, average='macro')\n",
        "rec_mlp = recall_score(y_true_mlp, y_pred_mlp, average='macro')\n",
        "f1_mlp = f1_score(y_true_mlp, y_pred_mlp, average='macro')\n",
        "\n",
        "# ROC AUC untuk MLP\n",
        "try:\n",
        "    auc_mlp = roc_auc_score(y_true_mlp, y_score_mlp, multi_class='ovo', average='macro')\n",
        "except:\n",
        "    auc_mlp = 'Error (label mismatch)'\n",
        "\n",
        "# Output hasil evaluasi\n",
        "print(f\"MLP Accuracy: {acc_mlp:.4f}\")\n",
        "print(f\"MLP Precision: {prec_mlp:.4f}\")\n",
        "print(f\"MLP Recall: {rec_mlp:.4f}\")\n",
        "print(f\"MLP F1 Score: {f1_mlp:.4f}\")\n",
        "print(f\"MLP AUC Score: {auc_mlp}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkH150K-DnVk",
        "outputId": "b6ea4b21-8b81-416d-eca1-0d409b5506f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Accuracy: 0.4429\n",
            "MLP Precision: 0.4642\n",
            "MLP Recall: 0.4429\n",
            "MLP F1 Score: 0.4261\n",
            "MLP AUC Score: 0.8604015777777779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi akurasi ke persentase\n",
        "acc_percent_mlp = acc_mlp * 100\n",
        "print(f\"MLP Accuracy (in %): {acc_percent_mlp:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3jKwi4KD69U",
        "outputId": "862ddd0c-c506-46ca-f3bf-509d28f12bae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Accuracy (in %): 44.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kesimpulan\n",
        "\n",
        "Berdasarkan hasil evaluasi yang diperoleh dari model **CNN** dan **MLP** pada dataset **CIFAR-10**, berikut adalah beberapa poin utama yang dapat disimpulkan:\n",
        "\n",
        "## 1. **Model CNN:**\n",
        "- **Akurasi**: Model CNN mencapai akurasi **82.56%**, yang menunjukkan bahwa model ini cukup baik dalam mengenali pola dan fitur pada dataset CIFAR-10.\n",
        "- **Precision**: Dengan **83.06%**, model CNN memiliki precision yang baik, artinya sebagian besar prediksi positif yang dilakukan oleh model benar-benar positif.\n",
        "- **Recall**: **82.56%**, yang menunjukkan bahwa model mampu mendeteksi sebagian besar data positif yang ada.\n",
        "- **F1 Score**: **82.32%**, ini menunjukkan keseimbangan yang baik antara precision dan recall. Model CNN mampu menjaga kinerja baik pada kedua metrik tersebut.\n",
        "- **AUC Score**: **98.33%**, yang sangat tinggi dan menunjukkan bahwa model CNN memiliki kemampuan sangat baik dalam membedakan antara kelas-kelas yang ada, dengan sedikit kesalahan dalam memprediksi kelas negatif.\n",
        "\n",
        "## 2. **Model MLP:**\n",
        "- **Akurasi**: Model MLP hanya mencapai **44.29%** akurasi, yang jauh lebih rendah dibandingkan dengan CNN. Hal ini menunjukkan bahwa MLP kurang efektif untuk tugas klasifikasi gambar seperti CIFAR-10.\n",
        "- **Precision**: Dengan **46.42%**, MLP menunjukkan kemampuan yang terbatas dalam memberikan prediksi positif yang benar.\n",
        "- **Recall**: **44.29%**, ini menunjukkan bahwa MLP kurang mampu mendeteksi sebagian besar data positif yang ada.\n",
        "- **F1 Score**: **42.61%**, yang juga mencerminkan bahwa model ini tidak seimbang dalam hal precision dan recall.\n",
        "- **AUC Score**: **86.04%**, meskipun lebih rendah dari CNN, AUC untuk MLP masih menunjukkan bahwa model ini cukup baik dalam membedakan kelas-kelas, meskipun tidak sebaik CNN.\n",
        "\n",
        "## 3. **Kesimpulan Umum:**\n",
        "- **CNN** menunjukkan kinerja yang jauh lebih baik dibandingkan dengan **MLP** pada dataset **CIFAR-10**, dengan akurasi yang jauh lebih tinggi dan metrik evaluasi lainnya yang mendekati nilai maksimum.\n",
        "- **MLP**, meskipun lebih sederhana, kesulitan untuk mencapai hasil yang baik pada tugas klasifikasi gambar yang kompleks. Ini menunjukkan bahwa **MLP tidak cocok untuk menangani data gambar**, karena tidak memiliki mekanisme untuk menangkap fitur spasial dalam gambar seperti yang dilakukan oleh **CNN**.\n",
        "- Oleh karena itu, untuk tugas klasifikasi gambar yang kompleks seperti CIFAR-10, **CNN adalah pilihan yang lebih baik** karena dapat memanfaatkan fitur spasial dan hubungan antar piksel dalam gambar.\n",
        "\n",
        "Secara keseluruhan, **CNN** terbukti lebih unggul dalam mengatasi masalah klasifikasi gambar pada dataset CIFAR-10.\n"
      ],
      "metadata": {
        "id": "tK5meGQrRrKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Penjelasan Persamaan Matematika\n",
        "## 1. **Cross-Entropy Loss (Loss Function)**\n",
        "Cross-Entropy Loss digunakan untuk mengukur perbedaan antara distribusi probabilitas prediksi model dan distribusi probabilitas label yang sebenarnya.\n",
        "\n",
        "$$\n",
        "\\text{Loss} = - \\sum_{i=1}^{N} y_i \\cdot \\log(p_i)\n",
        "$$\n",
        "\n",
        "- \\( y_i \\): Nilai sebenarnya (label) untuk kelas ke-\\(i\\) (biasanya dalam bentuk one-hot encoding).\n",
        "- \\( p_i \\): Probabilitas prediksi untuk kelas ke-\\(i\\) (hasil dari fungsi Softmax).\n",
        "- \\( N \\): Jumlah kelas.\n",
        "- **Fungsi ini mengukur seberapa baik model dalam memprediksi kelas yang benar.** Semakin kecil nilai loss, semakin baik performa model.\n",
        "\n",
        "## 2. **Accuracy**\n",
        "Akurasi mengukur seberapa banyak prediksi yang benar dibandingkan dengan total data yang ada.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Jumlah Prediksi Benar}}{\\text{Jumlah Data Total}}\n",
        "$$\n",
        "\n",
        "- **Akurasi** menunjukkan **seberapa sering model memberikan prediksi yang benar**.\n",
        "\n",
        "## 3. **Precision**\n",
        "Precision mengukur seberapa banyak prediksi yang benar untuk kelas positif dibandingkan dengan jumlah semua prediksi positif.\n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "- \\( TP \\) (True Positives): Jumlah kasus di mana model dengan benar memprediksi kelas positif.\n",
        "- \\( FP \\) (False Positives): Jumlah kasus di mana model salah memprediksi kelas positif (seharusnya negatif).\n",
        "- Precision menunjukkan **seberapa banyak prediksi positif yang benar** dari total prediksi positif yang dibuat oleh model.\n",
        "\n",
        "## 4. **Recall**\n",
        "Recall mengukur seberapa banyak data positif yang benar-benar terdeteksi oleh model dari semua data yang seharusnya positif.\n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "- \\( FN \\) (False Negatives): Jumlah kasus di mana model salah memprediksi kelas negatif padahal data tersebut seharusnya positif.\n",
        "- Recall menunjukkan **seberapa baik model dalam mendeteksi kelas positif**.\n",
        "\n",
        "## 5. **F1 Score**\n",
        "F1 Score adalah rata-rata harmonis dari Precision dan Recall. F1 score memberikan gambaran yang lebih lengkap mengenai keseimbangan antara Precision dan Recall.\n",
        "\n",
        "$$\n",
        "\\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "- F1 score memberikan **ukuran tunggal** yang menggambarkan keseimbangan antara Precision dan Recall. Nilai F1 akan mendekati 1 jika kedua metrik tersebut tinggi.\n",
        "\n",
        "## 6. **AUC (Area Under Curve) dan ROC (Receiver Operating Characteristic)**\n",
        "AUC adalah **area di bawah kurva ROC**. Kurva ROC menunjukkan hubungan antara **True Positive Rate (TPR)** dan **False Positive Rate (FPR)**, yang digunakan untuk mengukur kinerja model dalam membedakan antara kelas positif dan negatif.\n",
        "\n",
        "$$\n",
        "\\text{TPR (Recall)} = \\frac{TP}{TP + FN}, \\quad \\text{FPR} = \\frac{FP}{FP + TN}\n",
        "$$\n",
        "\n",
        "- **AUC** mengukur seberapa baik model dapat memisahkan antara kelas positif dan kelas negatif. Nilai AUC mendekati 1 berarti model sangat baik dalam membedakan kedua kelas.\n",
        "- **ROC Curve** adalah grafik yang menggambarkan hubungan antara TPR dan FPR pada berbagai threshold.\n",
        "\n",
        "## 7. **Softmax Function**\n",
        "Softmax digunakan pada model klasifikasi multi-kelas untuk menghasilkan probabilitas dari output yang tidak terdistribusi secara probabilistik.\n",
        "\n",
        "$$\n",
        "\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}\n",
        "$$\n",
        "\n",
        "- \\( z_i \\) adalah skor mentah (logit) untuk kelas ke-\\(i\\).\n",
        "- \\( K \\) adalah jumlah total kelas.\n",
        "- Softmax mengubah nilai logit menjadi nilai probabilitas antara 0 dan 1, yang menjumlahkan seluruh probabilitas untuk kelas-kelas menjadi 1.\n",
        "\n",
        "---\n",
        "\n",
        "# Ringkasan\n",
        "- **Cross-Entropy Loss** digunakan untuk menghitung seberapa baik model dalam memprediksi distribusi probabilitas untuk kelas-kelas.\n",
        "- **Akurasi** menunjukkan seberapa sering model memprediksi dengan benar.\n",
        "- **Precision** dan **Recall** mengukur kualitas prediksi positif, dengan Precision lebih fokus pada **keakuratan** prediksi positif dan Recall lebih pada **kemampuan mendeteksi** positif.\n",
        "- **F1 Score** menggabungkan Precision dan Recall untuk memberikan satu metrik.\n",
        "- **AUC** dan **ROC Curve** menggambarkan seberapa baik model membedakan antara kelas-kelas yang berbeda.\n",
        "\n",
        "Metrik-metrik ini sangat penting dalam mengevaluasi performa model, terutama dalam klasifikasi yang melibatkan lebih dari dua kelas atau ketidakseimbangan antara kelas.\n"
      ],
      "metadata": {
        "id": "qN6V-6vzQomq"
      }
    }
  ]
}